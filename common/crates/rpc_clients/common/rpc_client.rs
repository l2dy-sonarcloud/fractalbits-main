use bytes::{Bytes, BytesMut};
use metrics::{counter, gauge, histogram, Gauge};
use parking_lot::Mutex;
use std::collections::HashMap;
use std::io::{self};
use std::net::SocketAddr;
use std::os::fd::RawFd;
use std::os::unix::io::AsRawFd;
use std::sync::atomic::{AtomicBool, AtomicU32, Ordering};
use std::sync::Arc;
use std::time::{Duration, Instant};
use thiserror::Error;
use tokio::{
    self,
    io::AsyncWriteExt,
    net::tcp::{OwnedReadHalf, OwnedWriteHalf},
    net::TcpStream,
    sync::{
        mpsc::{self, Receiver, Sender},
        oneshot,
    },
    task::JoinSet,
};
use tokio_retry::strategy::jitter;
use tokio_stream::StreamExt;
use tokio_util::codec::FramedRead;

use crate::codec::{MessageFrame, MesssageCodec};
use crate::message::MessageHeader;
use rpc_client_common::ErrorRetryable;
use slotmap_conn_pool::Poolable;
use socket2::{Socket, TcpKeepalive};
use strum::AsRefStr;
use tokio_retry::{strategy::FixedInterval, Retry};
use tracing::{debug, error, warn};

#[cfg(feature = "nss")]
const RPC_TYPE: &str = "nss";
#[cfg(all(feature = "bss", not(feature = "nss")))]
const RPC_TYPE: &str = "bss";
#[cfg(all(feature = "rss", not(feature = "nss"), not(feature = "bss")))]
const RPC_TYPE: &str = "rss";
#[cfg(not(any(feature = "nss", feature = "bss", feature = "rss")))]
const RPC_TYPE: &str = "unknown";

#[derive(Error, Debug)]
pub enum RpcError {
    #[error(transparent)]
    IoError(#[from] io::Error),
    #[error(transparent)]
    OneshotRecvError(oneshot::error::RecvError),
    #[cfg(any(feature = "nss", feature = "rss"))]
    #[error(transparent)]
    EncodeError(prost::EncodeError),
    #[cfg(any(feature = "nss", feature = "rss"))]
    #[error(transparent)]
    DecodeError(prost::DecodeError),
    #[error("Internal request sending error: {0}")]
    InternalRequestError(String),
    #[error("Internal response error: {0}")]
    InternalResponseError(String),
    #[error("Entry not found")]
    NotFound,
    #[error("Entry already exists")]
    AlreadyExists,
    #[error("Send error: {0}")]
    SendError(String),
    #[cfg(feature = "rss")] // for rss txn api
    #[error("Retry")]
    Retry,
}

impl<T> From<mpsc::error::SendError<T>> for RpcError {
    fn from(e: mpsc::error::SendError<T>) -> Self {
        RpcError::SendError(e.to_string())
    }
}

impl ErrorRetryable for RpcError {
    fn retryable(&self) -> bool {
        matches!(self, RpcError::OneshotRecvError(_))
    }
}

#[allow(clippy::large_enum_variant)]
pub enum Message {
    Frame(MessageFrame),
    Bytes(Bytes),
}

pub struct RpcClient {
    requests: Arc<Mutex<HashMap<u32, oneshot::Sender<MessageFrame>>>>,
    sender: Sender<Message>,
    next_id: AtomicU32,
    #[allow(unused)]
    tasks: JoinSet<()>, // Use JoinSet to manage background tasks
    socket_fd: RawFd,
    is_closed: Arc<AtomicBool>,
}

impl Drop for RpcClient {
    fn drop(&mut self) {
        // Just try to make metrics (`rpc_request_pending_in_resp_map`) accurate
        Self::drain_pending_requests(self.socket_fd, &self.requests, DrainFrom::RpcClient);
    }
}

impl RpcClient {
    const MAX_CONNECTION_RETRIES: usize = 100 * 3600; // Max attempts to connect to an RPC server

    async fn resolve_address(addr_str: &str) -> Result<SocketAddr, io::Error> {
        // Try to parse as SocketAddr first (for backward compatibility with IP addresses)
        if let Ok(socket_addr) = addr_str.parse::<SocketAddr>() {
            return Ok(socket_addr);
        }

        // Use tokio's native async DNS resolution
        let mut addrs = tokio::net::lookup_host(addr_str).await?;
        addrs.next().ok_or_else(|| {
            io::Error::new(
                io::ErrorKind::NotFound,
                format!("No addresses found for '{addr_str}'"),
            )
        })
    }

    pub async fn new(stream: TcpStream) -> Result<Self, RpcError> {
        // Convert to std TcpStream, then to socket2 for advanced configuration
        let std_stream = stream.into_std()?;
        let socket = Socket::from(std_stream);

        // Set 16MB buffers for data-intensive operations
        socket.set_recv_buffer_size(16 * 1024 * 1024)?;
        socket.set_send_buffer_size(16 * 1024 * 1024)?;

        // Configure aggressive keepalive for internal network
        let keepalive = TcpKeepalive::new()
            .with_time(Duration::from_secs(5))
            .with_interval(Duration::from_secs(2))
            .with_retries(2);
        socket.set_tcp_keepalive(&keepalive)?;

        // Set TCP_NODELAY for low latency
        socket.set_nodelay(true)?;

        // Convert back to tokio TcpStream
        let std_stream: std::net::TcpStream = socket.into();
        std_stream.set_nonblocking(true)?;
        let stream = TcpStream::from_std(std_stream)?;

        let socket_fd = stream.as_raw_fd();
        let (receiver, sender) = stream.into_split();

        let requests = Arc::new(Mutex::new(HashMap::new()));
        let is_closed = Arc::new(AtomicBool::new(false));

        let mut tasks = JoinSet::new();

        // Start message receiver task, for rpc responses
        tasks.spawn({
            let requests_clone = requests.clone();
            let is_closed_clone = is_closed.clone();
            async move {
                if let Err(e) =
                    Self::receive_message_task(socket_fd, receiver, &requests_clone).await
                {
                    warn!(%socket_fd, error=%e, "receive message task quit");
                }
                is_closed_clone.store(true, Ordering::SeqCst);
                Self::drain_pending_requests(socket_fd, &requests_clone, DrainFrom::ReceiveTask);
            }
        });

        // Start message sender task, to send rpc requests. We are launching a dedicated task here
        // to reduce lock contention on the sender socket itself.
        let (tx, rx) = mpsc::channel(1024 * 1024);
        tasks.spawn({
            let is_closed_clone = is_closed.clone();
            let requests_clone = requests.clone();
            async move {
                if let Err(e) = Self::send_message_task(socket_fd, sender, rx).await {
                    warn!(%socket_fd, error=%e, "send message task quit");
                }
                is_closed_clone.store(true, Ordering::SeqCst);
                Self::drain_pending_requests(socket_fd, &requests_clone, DrainFrom::SendTask);
            }
        });

        Ok(Self {
            requests,
            sender: tx,
            next_id: AtomicU32::new(1),
            tasks,
            socket_fd,
            is_closed,
        })
    }

    async fn receive_message_task(
        socket_fd: RawFd,
        receiver: OwnedReadHalf,
        requests: &Arc<Mutex<HashMap<u32, oneshot::Sender<MessageFrame>>>>,
    ) -> Result<(), RpcError> {
        let decoder = MesssageCodec::default();
        let mut reader = FramedRead::new(receiver, decoder);
        while let Some(frame) = reader.next().await {
            let frame = frame?;
            let request_id = frame.header.id;
            debug!(%socket_fd, %request_id, "receiving response:");
            counter!("rpc_response_received", "type" => RPC_TYPE, "name" => "all").increment(1);
            let tx: oneshot::Sender<MessageFrame> = match requests.lock().remove(&frame.header.id) {
                Some(tx) => tx,
                None => {
                    warn!(%socket_fd, request_id=frame.header.id,
                            "received {RPC_TYPE} rpc message with id not in the resp_map");
                    continue;
                }
            };
            gauge!("rpc_request_pending_in_resp_map", "type" => RPC_TYPE).decrement(1.0);
            if tx.send(frame).is_err() {
                warn!(%socket_fd, %request_id, "oneshot response send failed");
            }
        }
        warn!(%socket_fd, "connection closed, receive message task quit");
        Ok(())
    }

    async fn send_message_task(
        socket_fd: RawFd,
        mut sender: OwnedWriteHalf,
        mut input: Receiver<Message>,
    ) -> Result<(), RpcError> {
        while let Some(message) = input.recv().await {
            gauge!("rpc_request_pending_in_send_queue", "type" => RPC_TYPE).decrement(1.0);
            match message {
                Message::Bytes(mut bytes) => {
                    sender.write_all_buf(&mut bytes).await?;
                }
                Message::Frame(mut frame) => {
                    let mut header_bytes = BytesMut::with_capacity(MessageHeader::SIZE);
                    frame.header.encode(&mut header_bytes);
                    sender.write_all_buf(&mut header_bytes).await?;
                    if !frame.body.is_empty() {
                        sender.write_all_buf(&mut frame.body).await?;
                    }
                }
            }
            sender.flush().await?;
            counter!("rpc_request_sent", "type" => RPC_TYPE, "name" => "all").increment(1);
        }
        warn!(%socket_fd, "connection closed, send_message_task quit");
        Ok(())
    }

    pub async fn send_request(
        &self,
        request_id: u32,
        msg: Message,
        timeout: Option<Duration>,
    ) -> Result<MessageFrame, RpcError> {
        let (tx, rx) = oneshot::channel();
        assert!(self.requests.lock().insert(request_id, tx).is_none());
        gauge!("rpc_request_pending_in_resp_map", "type" => RPC_TYPE).increment(1.0);

        self.sender.send(msg).await?;
        gauge!("rpc_request_pending_in_send_queue", "type" => RPC_TYPE).increment(1.0);
        debug!(%request_id, "request sent from handler:");

        let result = match timeout {
            None => rx.await,
            Some(rpc_timeout) => match tokio::time::timeout(rpc_timeout, rx).await {
                Ok(result) => result,
                Err(_) => {
                    warn!(socket_fd=%self.socket_fd, %request_id, "{RPC_TYPE} rpc request timeout");
                    return Err(RpcError::InternalResponseError("timeout".into()));
                }
            },
        };
        result.map_err(RpcError::OneshotRecvError)
    }

    pub fn gen_request_id(&self) -> u32 {
        self.next_id
            .fetch_add(1, std::sync::atomic::Ordering::SeqCst)
    }

    fn drain_pending_requests(
        socket_fd: RawFd,
        requests: &Arc<Mutex<HashMap<u32, oneshot::Sender<MessageFrame>>>>,
        drain_from: DrainFrom,
    ) {
        let mut requests = requests.lock();
        let pending_count = requests.len();
        if pending_count > 0 {
            warn!(
                %socket_fd,
                "draining {pending_count} pending requests from {} on connection close",
                drain_from.as_ref()
            );
            gauge!("rpc_request_pending_in_resp_map", "type" => RPC_TYPE)
                .decrement(pending_count as f64);
            requests.clear(); // This drops the senders, notifying receivers of an error.
        }
    }
}

#[derive(AsRefStr)]
#[strum(serialize_all = "snake_case")]
enum DrainFrom {
    SendTask,
    ReceiveTask,
    RpcClient,
}

impl Poolable for RpcClient {
    type AddrKey = String;
    type Error = Box<dyn std::error::Error + Send + Sync>; // Using Box<dyn Error> for simplicity

    async fn new(addr_key: Self::AddrKey) -> Result<Self, Self::Error> {
        let start = Instant::now();
        let retry_strategy = FixedInterval::from_millis(10)
            .map(jitter)
            .take(Self::MAX_CONNECTION_RETRIES);

        let stream = Retry::spawn(retry_strategy, || async {
            // Resolve DNS name to socket address for each connection attempt
            let socket_addr = Self::resolve_address(&addr_key).await?;
            TcpStream::connect(socket_addr).await
        })
        .await
        .map_err(|e| {
            warn!(rpc_type=RPC_TYPE, addr=%addr_key, error=%e, "failed to connect RPC server");
            Box::new(e) as Self::Error
        })?;

        let connect_duration = start.elapsed();
        if connect_duration > Duration::from_secs(1) {
            warn!(
                rpc_type=RPC_TYPE,
                addr=%addr_key,
                duration_ms=%connect_duration.as_millis(),
                "Slow connection establishment to RPC server"
            );
        } else if connect_duration > Duration::from_millis(100) {
            debug!(
                rpc_type=RPC_TYPE,
                addr=%addr_key,
                duration_ms=%connect_duration.as_millis(),
                "Connection established to RPC server"
            );
        }

        RpcClient::new(stream)
            .await
            .map_err(|e| Box::new(e) as Self::Error)
    }

    fn is_closed(&self) -> bool {
        self.is_closed.load(Ordering::SeqCst)
    }
}

pub struct InflightRpcGuard {
    start: Instant,
    gauge: Gauge,
    rpc_type: &'static str,
    rpc_name: &'static str,
}

impl InflightRpcGuard {
    pub fn new(rpc_type: &'static str, rpc_name: &'static str) -> Self {
        let gauge = gauge!("inflight_rpc", "type" => rpc_type, "name" => rpc_name);
        gauge.increment(1.0);
        counter!("rpc_request_sent", "type" => rpc_type, "name" => rpc_name).increment(1);

        Self {
            start: Instant::now(),
            gauge,
            rpc_type,
            rpc_name,
        }
    }
}

impl Drop for InflightRpcGuard {
    fn drop(&mut self) {
        histogram!("rpc_duration_nanos", "type" => self.rpc_type, "name" => self.rpc_name)
            .record(self.start.elapsed().as_nanos() as f64);
        self.gauge.decrement(1.0);
    }
}
